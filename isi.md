# ğŸ¯ SCikit-learn MASTER PREHÄ½AD

---

## ğŸ§  1. Generovanie a delenie dÃ¡t

```python
from sklearn import datasets
from sklearn.model_selection import train_test_split

# generovanie dÃ¡t
X, y = datasets.make_classification(
    n_samples=1000,
    n_features=3,
    n_redundant=0
)

# train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    stratify=y,
    random_state=0
)
```

---

## âš™ï¸ 2. Predspracovanie dÃ¡t (Preprocessing)

### 2.1 NormalizÃ¡cia a Å¡tandardizÃ¡cia
```python
from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer

StandardScaler()                       # Å¡tandardizÃ¡cia (z-score)
MinMaxScaler(feature_range=(0, 1))     # Å¡kÃ¡lovanie do rozsahu 0â€“1
Normalizer(norm='l2')                  # Ãºprava smerovÃ©ho typu (L1/L2)
```

#### PouÅ¾itie
```python
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)   # fit+transform na TRAIN
X_test_scaled = scaler.transform(X_test)         # len transform na TEST
```
ğŸ§  `fit_transform()` â†’ iba na X_train  
ğŸ§  `transform()` â†’ iba na X_test  
ğŸ§  nikdy nepouÅ¾Ã­vame na y

---

### 2.2 KvantilovÃ© a power transformÃ¡cie
```python
from sklearn.preprocessing import QuantileTransformer, PowerTransformer

QuantileTransformer(method="uniform", standardize=True)
PowerTransformer(method="yeo-johnson")
```

---

### 2.3 KÃ³dovanie kategÃ³riÃ­
```python
from sklearn.preprocessing import OneHotEncoder, LabelEncoder

OneHotEncoder(handle_unknown='ignore', sparse_output=False)
LabelEncoder()  # pouÅ¾Ã­va sa len na cieÄ¾ y
```

---

### 2.4 ImputÃ¡cia chÃ½bajÃºcich hodnÃ´t
```python
from sklearn.impute import SimpleImputer

SimpleImputer(strategy='median')
```

---

## ğŸŒ³ 3. Modely (Algoritmy uÄenia)

### Rozhodovacie stromy
```python
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor

DecisionTreeClassifier(criterion="gini", max_depth=None, random_state=42)
DecisionTreeRegressor(criterion="squared_error", max_depth=None, random_state=42)
```

### NÃ¡hodnÃ½ les
```python
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor

RandomForestClassifier(n_estimators=200, random_state=42)
RandomForestClassifier(n_estimators=100, random_state=100, max_features='sqrt')
RandomForestRegressor(n_estimators=100, random_state=100)
```

### Kâ€‘NajbliÅ¾Å¡Ã­ch susedov
```python
from sklearn.neighbors import KNeighborsClassifier

KNeighborsClassifier(metric='cosine', n_neighbors=5)
```

### Support Vector Machines (SVM)
```python
from sklearn.svm import SVC, SVR

SVC(kernel='linear', C=1.0, random_state=42)
SVR(kernel='linear', C=1.0)
```

### LogistickÃ¡ regresia
```python
from sklearn.linear_model import LogisticRegression

LogisticRegression(max_iter=1000, random_state=42)
```

---

## ğŸ“ˆ 4. VÃ½ber vlastnostÃ­ (Feature selection)
```python
from sklearn.feature_selection import SelectKBest, f_regression

SelectKBest(score_func=f_regression, k=10)
```

---

## ğŸ” 5. ValidÃ¡cia a krÃ­Å¾ovÃ¡ validÃ¡cia
```python
from sklearn.model_selection import KFold, RepeatedStratifiedKFold

KFold(n_splits=5)
RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)
```

ğŸ§  n_splits â€” poÄet foldov  
ğŸ§  n_repeats â€” poÄet opakovanÃ­ rozdelenÃ­

---

## ğŸ” 6. VyhÄ¾adÃ¡vanie parametrov (Grid Search)
```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    "C": [0.1, 1, 10],
    "gamma": ["scale", 0.01, 0.001]
}

grid = GridSearchCV(
    svc, param_grid=param_grid, scoring='accuracy', cv=5
)

grid.best_estimator_
grid.best_params_
grid.best_score_
```

---

## ğŸ¯ 7. Vyhodnocovanie modelu (Metriky a reporty)

### KlasifikaÄnÃ© metriky
```python
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, confusion_matrix, classification_report
)

accuracy_score(y_test, y_pred)
precision_score(y_test, y_pred)
recall_score(y_test, y_pred)
f1_score(y_test, y_pred)
cm = confusion_matrix(y_test, y_pred)
rep = classification_report(y_test, y_pred)
```

### RegresnÃ© metriky
```python
import sklearn.metrics as metrics

metrics.r2_score(y_test, y_pred)
metrics.mean_absolute_error(y_test, y_pred)
```

---

## ğŸ”— 8. Pipeline â€“ fitovanie a predikcia naraz
```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

pipe = Pipeline([
    ("scaler", StandardScaler()),
    ("clf", LogisticRegression())
])

pipe.fit(X_train, y_train)      # Fitne scaler aj model
y_pred = pipe.predict(X_test)   # Automaticky transformuje test a predikuje
```

ğŸ§  V `Pipeline`:
- `fit()` â†’ fitne vÅ¡etky kroky + model
- `predict()` â†’ automaticky transformuje a predikuje

---

## ğŸ§® 9. Python utility
```python
import heapq

heapq.heappush(heap, (priority, counter, data))
```

---

## âœ… ZHRNUTIE HLAVNÃCH MYÅ LIENOK

| OperÃ¡cia | Na Äo sa pouÅ¾Ã­va | VolÃ¡Å¡ na |
|-----------|------------------|----------|
| fit_transform() | nauÄÃ­ + transformuje dÃ¡ta | X_train |
| transform() | pouÅ¾ije rovnakÃ© nastavenia | X_test |
| fit() | nauÄÃ­ model | X_train, y_train |
| predict() | predpovede | X_test |
| Pipeline.fit() | fitne vÅ¡etky kroky | X_train, y_train |
| Pipeline.predict() | transformuje + predikuje | X_test |